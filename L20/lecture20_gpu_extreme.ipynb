{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drcr_AcFtHL5"
      },
      "source": [
        "# Lecture 20 : GPU Extreme"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHx2OrIvmXF4"
      },
      "source": [
        "# **Switch runtime to a CPU**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6c9cEnHtNHk"
      },
      "source": [
        "## Clone the materials repo to access datafiles."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIPn3sFUs-P5",
        "outputId": "97f8eb53-2f73-4bdf-fc0d-87e66b1984c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'cmda3634_materials'...\n",
            "remote: Enumerating objects: 235, done.\u001b[K\n",
            "remote: Counting objects: 100% (196/196), done.\u001b[K\n",
            "remote: Compressing objects: 100% (173/173), done.\u001b[K\n",
            "remote: Total 235 (delta 86), reused 37 (delta 16), pack-reused 39 (from 1)\u001b[K\n",
            "Receiving objects: 100% (235/235), 47.75 MiB | 8.78 MiB/s, done.\n",
            "Resolving deltas: 100% (86/86), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://code.vt.edu/jasonwil/cmda3634_materials.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "2tigY9H_tPk_"
      },
      "outputs": [],
      "source": [
        "# copy the lecture 20 files to our working directory\n",
        "!cp cmda3634_materials/L20/* .\n",
        "# uncompress the .gz files\n",
        "!gzip -d *.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5xo7QwetmxQ"
      },
      "source": [
        "# Part 1 : Sequential Extreme"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZaVD9JwtdDE",
        "outputId": "3981a6a1-fc1e-46bb-ed79-a69df27faacb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing extreme.c\n"
          ]
        }
      ],
      "source": [
        "%%writefile extreme.c\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <math.h>\n",
        "#include <time.h>\n",
        "\n",
        "typedef unsigned char byte;\n",
        "\n",
        "// read data from a binary file\n",
        "void read_bin (byte* data, int num_bytes, char* filename, int header_size) {\n",
        "    byte header[header_size];\n",
        "    FILE* fptr;\n",
        "    int num_read;\n",
        "    // open the binary file for reading\n",
        "    fptr = fopen(filename,\"rb\");\n",
        "    // need to check for null\n",
        "    if (fptr == 0) {\n",
        "        printf (\"Error opening binary data file %s.\\n\",filename);\n",
        "        exit(1);\n",
        "    }\n",
        "    // read header\n",
        "    num_read = fread(header, sizeof(byte), header_size, fptr);\n",
        "    // read data\n",
        "    num_read = fread(data, sizeof(byte), num_bytes, fptr);\n",
        "    if (num_read != num_bytes) {\n",
        "        printf (\"Warning : binary data file read error for %s.\\n\",filename);\n",
        "    }\n",
        "    // close the binary file\n",
        "    fclose(fptr);\n",
        "}\n",
        "\n",
        "typedef struct {\n",
        "    int max_dist_sq;\n",
        "    int i,j;\n",
        "} extreme_info;\n",
        "\n",
        "int vec_dist_sq(byte* u, byte* v, int dim) {\n",
        "    int dist_sq = 0;\n",
        "    for (int i=0;i<dim;i++) {\n",
        "\t    dist_sq += (u[i]-v[i])*(u[i]-v[i]);\n",
        "    }\n",
        "    return dist_sq;\n",
        "}\n",
        "\n",
        "int main (int argc, char** argv) {\n",
        "\n",
        "    // read in a MNIST image set\n",
        "    int len = 60000;\n",
        "    int dim = 784;\n",
        "    byte* data = (byte*)malloc(len*dim*sizeof(byte));\n",
        "    char images_file[] = \"train-images-idx3-ubyte\";\n",
        "    read_bin(data,len*dim,images_file,16);\n",
        "\n",
        "    // start the timer\n",
        "    clock_t start = clock();\n",
        "\n",
        "    // find the extreme pair\n",
        "    extreme_info info = { 0, -1, -1 };\n",
        "    for (int i=0;i<len-1;i++) {\n",
        "\t    for (int j=i+1;j<len;j++) {\n",
        "\t        int dist_sq = vec_dist_sq(data+i*dim,data+j*dim,dim);\n",
        "\t        if (dist_sq > info.max_dist_sq) {\n",
        "\t\t        info.max_dist_sq = dist_sq;\n",
        "\t\t        info.i = i;\n",
        "\t\t        info.j = j;\n",
        "\t        }\n",
        "\t    }\n",
        "    }\n",
        "\n",
        "    // stop the timer\n",
        "    clock_t stop = clock();\n",
        "    double elapsed = (double)(stop-start)/CLOCKS_PER_SEC;\n",
        "\n",
        "    // print results\n",
        "    printf (\"number of images = %d\\n\",len);\n",
        "    printf (\"elapsed time = %.4f seconds\\n\",elapsed);\n",
        "    printf (\"extreme distance = %.2f\\n\",sqrt(info.max_dist_sq));\n",
        "    printf (\"extreme pair = (%d,%d)\\n\",info.i,info.j);\n",
        "\n",
        "    // free dynamically allocated memory\n",
        "    free(data);\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lGJrD7ibuOb_"
      },
      "outputs": [],
      "source": [
        "!gcc -O3 -o extreme extreme.c -lm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dUB9qBkluRd1",
        "outputId": "2b40eb91-47ab-40a3-f964-9862dcd77686"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "number of images = 60000\n",
            "elapsed time = 203.6425 seconds\n",
            "extreme distance = 4303.32\n",
            "extreme pair = (26785,59452)\n"
          ]
        }
      ],
      "source": [
        "!./extreme"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnNZF4Dd4JA4"
      },
      "source": [
        "## Note that we are reading in the binary version of the MNIST image file rather than the text version.\n",
        "\n",
        "## Binary files take up less space than text files and they load faster as well."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFj_9tNTudUX"
      },
      "source": [
        "# Part 2 : GPU Extreme (Max Distance Only)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETL1dCG_33g5"
      },
      "source": [
        "## We start by writing a version that just computes the maximum distance squared over all pairs.  \n",
        "\n",
        "## Note that each thread computes the distance squared between a single pair of points.\n",
        "\n",
        "## Also note that a thread only considers its assigned pair if i < j.  \n",
        "\n",
        "## Since the *vec_dist_sq* function runs on the device we have to declare the function as:\n",
        "\n",
        "    __device__ int vec_dist_sq(byte* u, byte* v, int dim) {\n",
        "\n",
        "## Note the use of *atomicMax* to keep track of max_dist_sq.\n",
        "\n",
        "## When working with data on a GPU it is easy to run out of device memory.  \n",
        "\n",
        "##Thus, to be safe it is best to check the return value of cudaMalloc for NULL."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFQvs2SPe4j5"
      },
      "source": [
        "# **Switch runtime to a T4**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tK_BHZgBetnt",
        "outputId": "c88b3a6e-7acf-4f2f-be71-fa109326334d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'cmda3634_materials'...\n",
            "remote: Enumerating objects: 235, done.\u001b[K\n",
            "remote: Counting objects: 100% (196/196), done.\u001b[K\n",
            "remote: Compressing objects: 100% (173/173), done.\u001b[K\n",
            "remote: Total 235 (delta 86), reused 37 (delta 16), pack-reused 39 (from 1)\u001b[K\n",
            "Receiving objects: 100% (235/235), 47.75 MiB | 8.49 MiB/s, done.\n",
            "Resolving deltas: 100% (86/86), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://code.vt.edu/jasonwil/cmda3634_materials.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "OfJ-OT0Uewnc"
      },
      "outputs": [],
      "source": [
        "# copy the lecture 20 files to our working directory\n",
        "!cp cmda3634_materials/L20/* .\n",
        "# uncompress the .gz files\n",
        "!gzip -d *.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7MneUnhujF9",
        "outputId": "af977a92-ff37-4dde-df2a-745cb4316abd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing gpu_extreme_v1.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile gpu_extreme_v1.cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <time.h>\n",
        "#include <cuda.h>\n",
        "\n",
        "typedef unsigned char byte;\n",
        "\n",
        "// read data from a binary file\n",
        "void read_bin (byte* data, int num_bytes, char* filename, int header_size) {\n",
        "    byte header[header_size];\n",
        "    FILE* fptr;\n",
        "    int num_read;\n",
        "    // open the binary file for reading\n",
        "    fptr = fopen(filename,\"rb\");\n",
        "    // need to check for null\n",
        "    if (fptr == 0) {\n",
        "        printf (\"Error opening binary data file %s.\\n\",filename);\n",
        "        exit(1);\n",
        "    }\n",
        "    // read header\n",
        "    num_read = fread(header, sizeof(byte), header_size, fptr);\n",
        "    // read data\n",
        "    num_read = fread(data, sizeof(byte), num_bytes, fptr);\n",
        "    if (num_read != num_bytes) {\n",
        "        printf (\"Warning : binary data file read error for %s.\\n\",filename);\n",
        "    }\n",
        "    // close the binary file\n",
        "    fclose(fptr);\n",
        "}\n",
        "\n",
        "__device__ int vec_dist_sq(byte* u, byte* v, int dim) {\n",
        "    int dist_sq = 0;\n",
        "    for (int i=0;i<dim;i++) {\n",
        "\t    dist_sq += (u[i]-v[i])*(u[i]-v[i]);\n",
        "    }\n",
        "    return dist_sq;\n",
        "}\n",
        "\n",
        "__global__ void extremeKernel(byte* data, int len, int dim, int* max_dist_sq) {\n",
        "    int thread_num = blockIdx.x*blockDim.x + threadIdx.x;\n",
        "    if (thread_num < len*len) {\n",
        "\t    int i = thread_num/len;\n",
        "\t    int j = thread_num%len;\n",
        "\t    if (i < j) {\n",
        "\t        int dist_sq = vec_dist_sq(data+i*dim,data+j*dim,dim);\n",
        "\t        atomicMax(max_dist_sq,dist_sq);\n",
        "\t    }\n",
        "    }\n",
        "}\n",
        "\n",
        "int main (int argc, char** argv) {\n",
        "\n",
        "    // read in a MNIST image set\n",
        "    int len = 10000;\n",
        "    int dim = 784;\n",
        "    byte* data = (byte*)malloc(len*dim*sizeof(byte));\n",
        "    char images_file[] = \"t10k-images-idx3-ubyte\";\n",
        "    read_bin(data,len*dim,images_file,16);\n",
        "\n",
        "    // allocate device memory\n",
        "    byte* d_data;\n",
        "    int* d_max_dist_sq;\n",
        "    cudaMalloc(&d_data,len*dim*sizeof(byte));\n",
        "    if (d_data == NULL) {\n",
        "\t    printf (\"cudaMalloc failed\\n\");\n",
        "\t    return 1;\n",
        "    }\n",
        "    cudaMalloc(&d_max_dist_sq,sizeof(int));\n",
        "    if (d_max_dist_sq == NULL) {\n",
        "\t    printf (\"cudaMalloc failed\\n\");\n",
        "\t    return 1;\n",
        "    }\n",
        "\n",
        "    // start the timer\n",
        "    clock_t start = clock();\n",
        "\n",
        "    // copy data to device\n",
        "    cudaMemcpy(d_data,data,len*dim*sizeof(byte),cudaMemcpyHostToDevice);\n",
        "\n",
        "    // initialize the device max_dist_sq to 0\n",
        "    cudaMemset(d_max_dist_sq,0,sizeof(int));\n",
        "\n",
        "    // launch kernel to compute extreme distance\n",
        "    int B = 256;\n",
        "    int G = (len*len+B-1)/B;\n",
        "    extremeKernel <<< G, B >>> (d_data,len,dim,d_max_dist_sq);\n",
        "\n",
        "    // copy max_dist_sq from device to host\n",
        "    int max_dist_sq;\n",
        "    cudaMemcpy(&max_dist_sq,d_max_dist_sq,sizeof(int),cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // stop the timer\n",
        "    clock_t stop = clock();\n",
        "    double elapsed = (double)(stop-start)/CLOCKS_PER_SEC;\n",
        "\n",
        "    // print results\n",
        "    printf (\"number of images = %d\\n\",len);\n",
        "    printf (\"elapsed time = %.4f seconds\\n\",elapsed);\n",
        "    printf (\"extreme distance = %.2f\\n\",sqrt(max_dist_sq));\n",
        "\n",
        "    // free dynamically allocated memory\n",
        "    free(data);\n",
        "    cudaFree(d_data);\n",
        "    cudaFree(d_max_dist_sq);\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "V7TRmfQIvU3l"
      },
      "outputs": [],
      "source": [
        "!nvcc -arch=sm_75 -o gpu_extreme_v1 gpu_extreme_v1.cu"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./gpu_extreme_v1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-tdZbh6XFru",
        "outputId": "6380fa4c-153c-47da-ae63-fef1290c861b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of images = 10000\n",
            "elapsed time = 0.7996 seconds\n",
            "extreme distance = 4097.95\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eoEsUXxzfJu5"
      },
      "source": [
        "# **Disconnect and Delete T4 Runtime**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lo746N4Yv9Z4"
      },
      "source": [
        "# Part 3 : GPU Extreme (Max Distance and Extreme Pair)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFeKSuvR4kSc"
      },
      "source": [
        "## In CUDA there is no equivalent to an OpenMP critical region.\n",
        "\n",
        "## Thus, we frequently have to get creative to get the most out of the GPU atomics.\n",
        "\n",
        "## In order to do an *atomic update* of the triple\n",
        "\n",
        "$$(max\\_dist\\_sq, i, j)$$\n",
        "\n",
        "## we pack the three values $max\\_dist\\_sq$, $i$, and $j$ into an *unsigned long long* which is 64 bits.  \n",
        "\n",
        "## We use 32 of the 64 bits to store $\\max\\_dist\\_sq$ and 16 bits each to store $i$ and $j$.\n",
        "\n",
        "## We put $max\\_dist\\_sq$ in the high 32 bits so that the *atomicMax* will still work as expected.  \n",
        "\n",
        "## The extreme pair $(i,j)$ is tucked into the low 32 bits and will not effect the *atomicMax* calculation (unless there is a tie).\n",
        "\n",
        "## Note that there is a function to *compress* a triple of extreme info and a function to *expand* an unsigned long long into a triple of extreme info.  \n",
        "\n",
        "## Since the *compress* function runs on the device we have to declare the function as:\n",
        "\n",
        "    __device__ uint64 extreme_info_compress(int dist_sq, int i, int j) {"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qetQOfagJkr"
      },
      "source": [
        "# **Reconnect to a T4 by running commands below.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5ua1UQugUPC",
        "outputId": "bf6af42a-11b9-4acc-b5be-84968dc7bd53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'cmda3634_materials'...\n",
            "remote: Enumerating objects: 235, done.\u001b[K\n",
            "remote: Counting objects: 100% (196/196), done.\u001b[K\n",
            "remote: Compressing objects: 100% (173/173), done.\u001b[K\n",
            "remote: Total 235 (delta 86), reused 37 (delta 16), pack-reused 39 (from 1)\u001b[K\n",
            "Receiving objects: 100% (235/235), 47.75 MiB | 8.72 MiB/s, done.\n",
            "Resolving deltas: 100% (86/86), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://code.vt.edu/jasonwil/cmda3634_materials.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Bkgm7RQ9gT8U"
      },
      "outputs": [],
      "source": [
        "# copy the lecture 20 files to our working directory\n",
        "!cp cmda3634_materials/L20/* .\n",
        "# uncompress the .gz files\n",
        "!gzip -d *.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFnRqbCJvYum",
        "outputId": "de671f01-f1d2-4d65-b73d-e1bc8a20eaaa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting gpu_extreme_v2.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile gpu_extreme_v2.cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <time.h>\n",
        "#include <cuda.h>\n",
        "\n",
        "typedef unsigned char byte;\n",
        "typedef unsigned long long uint64;\n",
        "\n",
        "// read data from a binary file\n",
        "void read_bin (byte* data, int num_bytes, char* filename, int header_size) {\n",
        "    byte header[header_size];\n",
        "    FILE* fptr;\n",
        "    int num_read;\n",
        "    // open the binary file for reading\n",
        "    fptr = fopen(filename,\"rb\");\n",
        "    // need to check for null\n",
        "    if (fptr == 0) {\n",
        "        printf (\"Error opening binary data file %s.\\n\",filename);\n",
        "        exit(1);\n",
        "    }\n",
        "    // read header\n",
        "    num_read = fread(header, sizeof(byte), header_size, fptr);\n",
        "    // read data\n",
        "    num_read = fread(data, sizeof(byte), num_bytes, fptr);\n",
        "    if (num_read != num_bytes) {\n",
        "        printf (\"Warning : binary data file read error for %s.\\n\",filename);\n",
        "    }\n",
        "    // close the binary file\n",
        "    fclose(fptr);\n",
        "}\n",
        "\n",
        "__device__ int vec_dist_sq(byte* u, byte* v, int dim) {\n",
        "    int dist_sq = 0;\n",
        "    for (int i=0;i<dim;i++) {\n",
        "\t    dist_sq += (u[i]-v[i])*(u[i]-v[i]);\n",
        "    }\n",
        "    return dist_sq;\n",
        "}\n",
        "\n",
        "void extreme_info_expand(uint64 info, int* dist_sq, int* i, int* j) {\n",
        "    *j = info & 0xFFFF; // apply bit mask to zero out all but lower 16 bits\n",
        "    info = info >> 16; // shift 16 bits to the left\n",
        "    *i = info & 0xFFFF; // apply bit mask to zero out all but lower 16 bits\n",
        "    info = info >> 16; // shift 16 bits to the left\n",
        "    *dist_sq = info;\n",
        "}\n",
        "\n",
        "__device__ uint64 extreme_info_compress(int dist_sq, int i, int j) {\n",
        "    uint64 info = dist_sq;\n",
        "    info = info << 16; // shift 16 bits to the right\n",
        "    info += i;\n",
        "    info = info << 16; // shift 16 bits to the right\n",
        "    info += j;\n",
        "    return info;\n",
        "}\n",
        "\n",
        "__global__ void extremeKernel(byte* data, int len, int dim, uint64* max_info) {\n",
        "    int thread_num = blockIdx.x*blockDim.x + threadIdx.x;\n",
        "    if (thread_num < len*len) {\n",
        "\t    int i = thread_num/len;\n",
        "\t    int j = thread_num%len;\n",
        "\t    if (i < j) {\n",
        "\t        int dist_sq = vec_dist_sq(data+i*dim,data+j*dim,dim);\n",
        "\t        uint64 info = extreme_info_compress(dist_sq,i,j);\n",
        "\t        atomicMax(max_info,info);\n",
        "\t    }\n",
        "    }\n",
        "}\n",
        "\n",
        "int main (int argc, char** argv) {\n",
        "\n",
        "    // read in a MNIST image set\n",
        "    int len = 10000;\n",
        "    int dim = 784;\n",
        "    byte* data = (byte*)malloc(len*dim*sizeof(byte));\n",
        "    char images_file[] = \"t10k-images-idx3-ubyte\";\n",
        "    read_bin(data,len*dim,images_file,16);\n",
        "\n",
        "    // allocate device memory\n",
        "    byte* d_data;\n",
        "    uint64* d_max_info;\n",
        "    cudaMalloc(&d_data,len*dim*sizeof(byte));\n",
        "    if (d_data == NULL) {\n",
        "\t    printf (\"cudaMalloc failed\\n\");\n",
        "\t    return 1;\n",
        "    }\n",
        "    cudaMalloc(&d_max_info,sizeof(uint64));\n",
        "    if (d_max_info == NULL) {\n",
        "\t    printf (\"cudaMalloc failed\\n\");\n",
        "\t    return 1;\n",
        "    }\n",
        "\n",
        "    // start the timer\n",
        "    clock_t start = clock();\n",
        "\n",
        "    // copy data to device\n",
        "    cudaMemcpy(d_data,data,len*dim*sizeof(byte),cudaMemcpyHostToDevice);\n",
        "\n",
        "    // initialize the device max_info to 0\n",
        "    cudaMemset(d_max_info,0,sizeof(uint64));\n",
        "\n",
        "    // launch kernel to compute extreme distance\n",
        "    int B = 256;\n",
        "    int G = (len*len+B-1)/B;\n",
        "    extremeKernel <<< G, B >>> (d_data,len,dim,d_max_info);\n",
        "\n",
        "    // copy max_info from device to host\n",
        "    uint64 max_info;\n",
        "    cudaMemcpy(&max_info,d_max_info,sizeof(uint64),cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // stop the timer\n",
        "    clock_t stop = clock();\n",
        "    double elapsed = (double)(stop-start)/CLOCKS_PER_SEC;\n",
        "\n",
        "    // expand max_info\n",
        "    int max_dist_sq, i, j;\n",
        "    extreme_info_expand(max_info,&max_dist_sq,&i,&j);\n",
        "\n",
        "    // print results\n",
        "    printf (\"number of images = %d\\n\",len);\n",
        "    printf (\"elapsed time = %.4f seconds\\n\",elapsed);\n",
        "    printf (\"extreme distance = %.2f\\n\",sqrt(max_dist_sq));\n",
        "    printf (\"extreme pair = (%d,%d)\\n\",i,j);\n",
        "\n",
        "    // free dynamically allocated memory\n",
        "    free(data);\n",
        "    cudaFree(d_data);\n",
        "    cudaFree(d_max_info);\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Uz9ETgP3wruR"
      },
      "outputs": [],
      "source": [
        "!nvcc -arch=sm_75 -o gpu_extreme_v2 gpu_extreme_v2.cu"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./gpu_extreme_v2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLoq6VpdaFYt",
        "outputId": "a79051be-fdee-4b4d-b91f-f06dd4c6f7be"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of images = 10000\n",
            "elapsed time = 0.8064 seconds\n",
            "extreme distance = 4097.95\n",
            "extreme pair = (5977,6412)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGyhTPZGgSdv"
      },
      "source": [
        "# **Disconnect and Delete T4 Runtime**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rssxsYzsxIIj"
      },
      "source": [
        "# Part 4 : GPU Extreme (Column Major Order)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RqHEGno8jaD"
      },
      "source": [
        "## It is frequently better to use matrices stored in column major order in CUDA.\n",
        "\n",
        "## Ideally, consecutive threads in a warp will read consecutive memory locations when accessing memory.  \n",
        "\n",
        "## Suppose each thread in a warp is reading consecutive rows of a matrix.  \n",
        "\n",
        "## If the matrix is stored in *row major order* then consecutive threads in a warp are reading values that are stored far apart in memory.  \n",
        "\n",
        "## However if the matrix is stored in *column major order* then consecutive threads in a warp are reading values that are stored next to each other in memory."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYff3r5Phoi4"
      },
      "source": [
        "## The main difference to the code is where we calculate the distance between two vectors.\n",
        "\n",
        "## Here is the distance calculation when storing the data in **row major order**.\n",
        "\n",
        "    int dist_sq = 0;\n",
        "\tfor (int k=0;k<dim;k++) {\n",
        "\t\tint diff = data[i*dim+k]-data[j*dim+k];\n",
        "\t\tdist_sq += diff*diff;\n",
        "\t}\n",
        "\n",
        "## Here is the distance calculation when storing the data in **column major order**.\n",
        "\n",
        "    int dist_sq = 0;\n",
        "\tfor (int k=0;k<dim;k++) {\n",
        "        int diff = data[k*len+i]-data[k*len+j];\n",
        "\t\tdist_sq += diff*diff;\n",
        "\t}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhRy2nxChQpE"
      },
      "source": [
        "# **Reconnect to a T4 by running commands below.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ku8kpzXNhRrj",
        "outputId": "97eb6ccf-86dd-4a50-ec5c-38900cc8d61b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'cmda3634_materials'...\n",
            "remote: Enumerating objects: 235, done.\u001b[K\n",
            "remote: Counting objects: 100% (196/196), done.\u001b[K\n",
            "remote: Compressing objects: 100% (173/173), done.\u001b[K\n",
            "remote: Total 235 (delta 86), reused 37 (delta 16), pack-reused 39 (from 1)\u001b[K\n",
            "Receiving objects: 100% (235/235), 47.75 MiB | 8.73 MiB/s, done.\n",
            "Resolving deltas: 100% (86/86), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://code.vt.edu/jasonwil/cmda3634_materials.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "UN0rsUFWhV_l"
      },
      "outputs": [],
      "source": [
        "# copy the lecture 20 files to our working directory\n",
        "!cp cmda3634_materials/L20/* .\n",
        "# uncompress the .gz files\n",
        "!gzip -d *.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-VJ0Z4aw97S",
        "outputId": "449443cf-ce6a-470c-d107-14614c69f548"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing gpu_extreme_v3.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile gpu_extreme_v3.cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <time.h>\n",
        "#include <cuda.h>\n",
        "\n",
        "typedef unsigned char byte;\n",
        "typedef unsigned long long uint64;\n",
        "\n",
        "// read data from a binary file\n",
        "void read_bin (byte* data, int num_bytes, char* filename, int header_size) {\n",
        "    byte header[header_size];\n",
        "    FILE* fptr;\n",
        "    int num_read;\n",
        "    // open the binary file for reading\n",
        "    fptr = fopen(filename,\"rb\");\n",
        "    // need to check for null\n",
        "    if (fptr == 0) {\n",
        "        printf (\"Error opening binary data file %s.\\n\",filename);\n",
        "        exit(1);\n",
        "    }\n",
        "    // read header\n",
        "    num_read = fread(header, sizeof(byte), header_size, fptr);\n",
        "    // read data\n",
        "    num_read = fread(data, sizeof(byte), num_bytes, fptr);\n",
        "    if (num_read != num_bytes) {\n",
        "        printf (\"Warning : binary data file read error for %s.\\n\",filename);\n",
        "    }\n",
        "    // close the binary file\n",
        "    fclose(fptr);\n",
        "}\n",
        "\n",
        "void extreme_info_expand(uint64 info, int* dist_sq, int* i, int* j) {\n",
        "    *j = info & 0xFFFF; // apply bit mask to zero out all but lower 16 bits\n",
        "    info = info >> 16; // shift 16 bits to the left\n",
        "    *i = info & 0xFFFF; // apply bit mask to zero out all but lower 16 bits\n",
        "    info = info >> 16; // shift 16 bits to the left\n",
        "    *dist_sq = info;\n",
        "}\n",
        "\n",
        "__device__ uint64 extreme_info_compress(int dist_sq, int i, int j) {\n",
        "    uint64 info = dist_sq;\n",
        "    info = info << 16; // shift 16 bits to the right\n",
        "    info += i;\n",
        "    info = info << 16; // shift 16 bits to the right\n",
        "    info += j;\n",
        "    return info;\n",
        "}\n",
        "\n",
        "__global__ void extremeKernel(byte* data, int len, int dim, uint64* max_info) {\n",
        "    int thread_num = blockIdx.x*blockDim.x + threadIdx.x;\n",
        "    if (thread_num < len*len) {\n",
        "\t    int i = thread_num/len;\n",
        "\t    int j = thread_num%len;\n",
        "\t    if (i < j) {\n",
        "\t        int dist_sq = 0;\n",
        "\t        for (int k=0;k<dim;k++) {\n",
        "                int diff = data[k*len+i]-data[k*len+j];\n",
        "\t\t        dist_sq += diff*diff;\n",
        "\t        }\n",
        "\t        uint64 info = extreme_info_compress(dist_sq,i,j);\n",
        "\t        atomicMax(max_info,info);\n",
        "\t    }\n",
        "    }\n",
        "}\n",
        "\n",
        "int main (int argc, char** argv) {\n",
        "\n",
        "    // read in a MNIST image set\n",
        "    int len = 10000;\n",
        "    int dim = 784;\n",
        "    byte* data = (byte*)malloc(len*dim*sizeof(byte));\n",
        "    // read the file that thas the dataset stored in column major order\n",
        "    char images_file[] = \"t10k-images-idx3-ubyte-c\";\n",
        "    read_bin(data,len*dim,images_file,16);\n",
        "\n",
        "    // allocate device memory\n",
        "    byte* d_data;\n",
        "    uint64* d_max_info;\n",
        "    cudaMalloc(&d_data,len*dim*sizeof(byte));\n",
        "    if (d_data == NULL) {\n",
        "\t    printf (\"cudaMalloc failed\\n\");\n",
        "\t    return 1;\n",
        "    }\n",
        "    cudaMalloc(&d_max_info,sizeof(uint64));\n",
        "    if (d_max_info == NULL) {\n",
        "\t    printf (\"cudaMalloc failed\\n\");\n",
        "\t    return 1;\n",
        "    }\n",
        "\n",
        "    // start the timer\n",
        "    clock_t start = clock();\n",
        "\n",
        "    // copy data to device\n",
        "    cudaMemcpy(d_data,data,len*dim*sizeof(byte),cudaMemcpyHostToDevice);\n",
        "\n",
        "    // initialize the device max_info to 0\n",
        "    cudaMemset(d_max_info,0,sizeof(uint64));\n",
        "\n",
        "    // launch kernel to compute extreme distance\n",
        "    int B = 256;\n",
        "    int G = (len*len+B-1)/B;\n",
        "    extremeKernel <<< G, B >>> (d_data,len,dim,d_max_info);\n",
        "\n",
        "    // copy max_info from device to host\n",
        "    uint64 max_info;\n",
        "    cudaMemcpy(&max_info,d_max_info,sizeof(uint64),cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // stop the timer\n",
        "    clock_t stop = clock();\n",
        "    double elapsed = (double)(stop-start)/CLOCKS_PER_SEC;\n",
        "\n",
        "    // expand max_info\n",
        "    int max_dist_sq, i, j;\n",
        "    extreme_info_expand(max_info,&max_dist_sq,&i,&j);\n",
        "\n",
        "    // print results\n",
        "    printf (\"number of images = %d\\n\",len);\n",
        "    printf (\"elapsed time = %.4f seconds\\n\",elapsed);\n",
        "    printf (\"extreme distance = %.2f\\n\",sqrt(max_dist_sq));\n",
        "    printf (\"extreme pair = (%d,%d)\\n\",i,j);\n",
        "\n",
        "    // free dynamically allocated memory\n",
        "    free(data);\n",
        "    cudaFree(d_data);\n",
        "    cudaFree(d_max_info);\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "MmtZJ3UIxh52"
      },
      "outputs": [],
      "source": [
        "!nvcc -arch=sm_75 -o gpu_extreme_v3 gpu_extreme_v3.cu"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./gpu_extreme_v3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9FLmXdIcR8a",
        "outputId": "c24c668e-9e92-4744-806b-aa0fcaa0892c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of images = 10000\n",
            "elapsed time = 0.2364 seconds\n",
            "extreme distance = 4097.95\n",
            "extreme pair = (5977,6412)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_qwFN_WjN5t"
      },
      "source": [
        "# **Disconnect and Delete T4 Runtime**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvnRbIwYyAob"
      },
      "source": [
        "# Part 5 : GPU Extreme (60000 images)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PK8VztiL99SM"
      },
      "source": [
        "## When running on a file with 60000 images, there are 3.6 billion threads which is a number that is too large to store in a C int.  \n",
        "\n",
        "## Thus we have to change some parts of the code to avoid overflow.  \n",
        "\n",
        "## Here are the necessary changes:\n",
        "\n",
        "    long long thread_num = (long long)blockIdx.x*blockDim.x + threadIdx.x;\n",
        "\n",
        "    if (thread_num < (long long)len*len) {\n",
        "\n",
        "    int G = ((long long)len*len+B-1)/B;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTL5HzVtj9vx"
      },
      "source": [
        "# **Reconnect to a T4 by running commands below.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_69GIDBYj-sV",
        "outputId": "f28ceb7b-226b-413c-a1d9-a4a4ead9d794"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'cmda3634_materials'...\n",
            "remote: Enumerating objects: 235, done.\u001b[K\n",
            "remote: Counting objects: 100% (196/196), done.\u001b[K\n",
            "remote: Compressing objects: 100% (173/173), done.\u001b[K\n",
            "remote: Total 235 (delta 86), reused 37 (delta 16), pack-reused 39 (from 1)\u001b[K\n",
            "Receiving objects: 100% (235/235), 47.75 MiB | 8.53 MiB/s, done.\n",
            "Resolving deltas: 100% (86/86), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://code.vt.edu/jasonwil/cmda3634_materials.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "VPivRYOxj_E4"
      },
      "outputs": [],
      "source": [
        "# copy the lecture 20 files to our working directory\n",
        "!cp cmda3634_materials/L20/* .\n",
        "# uncompress the .gz files\n",
        "!gzip -d *.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TSl2PGcJxylk",
        "outputId": "e5caf7fd-9ece-426c-c54d-912309cfd7c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing gpu_extreme_v4.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile gpu_extreme_v4.cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <time.h>\n",
        "#include <cuda.h>\n",
        "\n",
        "typedef unsigned char byte;\n",
        "typedef unsigned long long uint64;\n",
        "\n",
        "// read data from a binary file\n",
        "void read_bin (byte* data, int num_bytes, char* filename, int header_size) {\n",
        "    byte header[header_size];\n",
        "    FILE* fptr;\n",
        "    int num_read;\n",
        "    // open the binary file for reading\n",
        "    fptr = fopen(filename,\"rb\");\n",
        "    // need to check for null\n",
        "    if (fptr == 0) {\n",
        "        printf (\"Error opening binary data file %s.\\n\",filename);\n",
        "        exit(1);\n",
        "    }\n",
        "    // read header\n",
        "    num_read = fread(header, sizeof(byte), header_size, fptr);\n",
        "    // read data\n",
        "    num_read = fread(data, sizeof(byte), num_bytes, fptr);\n",
        "    if (num_read != num_bytes) {\n",
        "        printf (\"Warning : binary data file read error for %s.\\n\",filename);\n",
        "    }\n",
        "    // close the binary file\n",
        "    fclose(fptr);\n",
        "}\n",
        "\n",
        "void extreme_info_expand(uint64 info, int* dist_sq, int* i, int* j) {\n",
        "    *j = info & 0xFFFF; // apply bit mask to zero out all but lower 16 bits\n",
        "    info = info >> 16; // shift 16 bits to the left\n",
        "    *i = info & 0xFFFF; // apply bit mask to zero out all but lower 16 bits\n",
        "    info = info >> 16; // shift 16 bits to the left\n",
        "    *dist_sq = info;\n",
        "}\n",
        "\n",
        "__device__ uint64 extreme_info_compress(int dist_sq, int i, int j) {\n",
        "    uint64 info = dist_sq;\n",
        "    info = info << 16; // shift 16 bits to the right\n",
        "    info += i;\n",
        "    info = info << 16; // shift 16 bits to the right\n",
        "    info += j;\n",
        "    return info;\n",
        "}\n",
        "\n",
        "__global__ void extremeKernel(byte* data, int len, int dim, uint64* max_info) {\n",
        "    long long thread_num = (long long)blockIdx.x*blockDim.x + threadIdx.x;\n",
        "    if (thread_num < (long long)len*len) {\n",
        "\t    int i = thread_num/len;\n",
        "\t    int j = thread_num%len;\n",
        "\t    if (i < j) {\n",
        "\t        int dist_sq = 0;\n",
        "\t        for (int k=0;k<dim;k++) {\n",
        "                int diff = data[k*len+i]-data[k*len+j];\n",
        "\t\t        dist_sq += diff*diff;\n",
        "\t        }\n",
        "\t        uint64 info = extreme_info_compress(dist_sq,i,j);\n",
        "\t        atomicMax(max_info,info);\n",
        "\t    }\n",
        "    }\n",
        "}\n",
        "\n",
        "int main (int argc, char** argv) {\n",
        "\n",
        "    // read in a MNIST image set\n",
        "    int len = 60000;\n",
        "    int dim = 784;\n",
        "    byte* data = (byte*)malloc(len*dim*sizeof(byte));\n",
        "    // read the file that thas the dataset stored in column major order\n",
        "    char images_file[] = \"train-images-idx3-ubyte-c\";\n",
        "    read_bin(data,len*dim,images_file,16);\n",
        "\n",
        "    // allocate device memory\n",
        "    byte* d_data;\n",
        "    uint64* d_max_info;\n",
        "    cudaMalloc(&d_data,len*dim*sizeof(byte));\n",
        "    if (d_data == NULL) {\n",
        "\t    printf (\"cudaMalloc failed\\n\");\n",
        "\t    return 1;\n",
        "    }\n",
        "    cudaMalloc(&d_max_info,sizeof(uint64));\n",
        "    if (d_max_info == NULL) {\n",
        "\t    printf (\"cudaMalloc failed\\n\");\n",
        "\t    return 1;\n",
        "    }\n",
        "\n",
        "    // start the timer\n",
        "    clock_t start = clock();\n",
        "\n",
        "    // copy data to device\n",
        "    cudaMemcpy(d_data,data,len*dim*sizeof(byte),cudaMemcpyHostToDevice);\n",
        "\n",
        "    // initialize the device max_info to 0\n",
        "    cudaMemset(d_max_info,0,sizeof(uint64));\n",
        "\n",
        "    // launch kernel to compute extreme distance\n",
        "    int B = 256;\n",
        "    int G = ((long long)len*len+B-1)/B;\n",
        "    extremeKernel <<< G, B >>> (d_data,len,dim,d_max_info);\n",
        "\n",
        "    // copy max_info from device to host\n",
        "    uint64 max_info;\n",
        "    cudaMemcpy(&max_info,d_max_info,sizeof(uint64),cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // stop the timer\n",
        "    clock_t stop = clock();\n",
        "    double elapsed = (double)(stop-start)/CLOCKS_PER_SEC;\n",
        "\n",
        "    // expand max_info\n",
        "    int max_dist_sq, i, j;\n",
        "    extreme_info_expand(max_info,&max_dist_sq,&i,&j);\n",
        "\n",
        "    // print results\n",
        "    printf (\"number of images = %d\\n\",len);\n",
        "    printf (\"elapsed time = %.4f seconds\\n\",elapsed);\n",
        "    printf (\"extreme distance = %.2f\\n\",sqrt(max_dist_sq));\n",
        "    printf (\"extreme pair = (%d,%d)\\n\",i,j);\n",
        "\n",
        "    // free dynamically allocated memory\n",
        "    free(data);\n",
        "    cudaFree(d_data);\n",
        "    cudaFree(d_max_info);\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "rOl5lZtPyQqs"
      },
      "outputs": [],
      "source": [
        "!nvcc -arch=sm_75 -o gpu_extreme_v4 gpu_extreme_v4.cu"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./gpu_extreme_v4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2QxvxDhdoAB",
        "outputId": "d3fcfb7b-027c-4078-d381-4230e570668f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of images = 60000\n",
            "elapsed time = 12.2280 seconds\n",
            "extreme distance = 4303.32\n",
            "extreme pair = (26785,59452)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjFBywyek3kP"
      },
      "source": [
        "# **Disconnect and Delete T4 Runtime**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 6 : GPU Extreme (with cuBLAS)"
      ],
      "metadata": {
        "id": "2fAu_pM-hA_f"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JD9lKnNx-xh9"
      },
      "source": [
        "## Although the GPU version 4 is considerably faster than the sequential code, we are not even close to realizing the maximum performance of the GPU for this problem.  \n",
        "\n",
        "## In the final version we will improve the performance drastically by leveraging the fact that GPUs are extremely fast at matrix multiplication when using special hardware called **Tensor Cores**."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Suppose we have *n* data points (e.g. images)\n",
        "## $$\\text{data }= \\{ \\mathbf{v}_1, \\mathbf{v}_2, \\ldots, \\mathbf{v}_n \\}$$\n",
        "## To find the extreme pair we need to compute roughly $O(n^2)$ squared distances:\n",
        "## $$\\| \\mathbf{v}_i - \\mathbf{v}_j \\|^2 =\n",
        "(\\mathbf{v}_i - \\mathbf{v}_j) \\cdot\n",
        "(\\mathbf{v}_i - \\mathbf{v}_j) =\n",
        "\\mathbf{v}_i \\cdot \\mathbf{v}_i - 2 \\mathbf{v}_i \\cdot \\mathbf{v}_j + \\mathbf{v}_j \\cdot \\mathbf{v}_j$$"
      ],
      "metadata": {
        "id": "xxjELGm4iACz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The majority of the work to be done is computing the $n^2$ dot products\n",
        "## $$\\mathbf{v}_i \\cdot \\mathbf{v}_j$$\n",
        "## The key observation is that we can turn computing those dot products into matrix multiplication.  \n",
        "## $$\\begin{bmatrix} \\mathbf{v}_1^T \\\\ \\mathbf{v}_2^T \\\\ \\vdots \\\\ \\mathbf{v}_n^T \\end{bmatrix}\n",
        "\\begin{bmatrix} \\mathbf{v}_1 & \\mathbf{v}_2 & \\cdots & \\mathbf{v}_n \\end{bmatrix} =\n",
        "\\begin{bmatrix} \\mathbf{v}_1 \\cdot \\mathbf{v}_1 & \\mathbf{v}_1 \\cdot \\mathbf{v}_2 & \\cdots & \\mathbf{v}_1 \\cdot \\mathbf{v}_n \\\\\n",
        "\\mathbf{v}_2 \\cdot \\mathbf{v}_1 & \\mathbf{v}_2 \\cdot \\mathbf{v}_2 & \\cdots & \\mathbf{v}_2 \\cdot \\mathbf{v}_n \\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
        "\\\\ \\mathbf{v}_n \\cdot \\mathbf{v}_1 & \\mathbf{v}_n \\cdot \\mathbf{v}_2 & \\cdots & \\mathbf{v}_n \\cdot \\mathbf{v}_n \\end{bmatrix}$$"
      ],
      "metadata": {
        "id": "_dEJWtyji3sb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## We use the function **cublasSgemm** to perform the above matrix multiplication.  \n",
        "## Here **Sgemm** stands for single precision general matrix multiply.  \n",
        "## This **cuBLAS** function allows us to take full advantage of the awesome number crunching capabilities of the GPU (including Tensor Cores!) without writing complicated CUDA kernels.\n",
        "## Note that to use **cuBLAS** our matrices have to be stored in **column major order**.  \n",
        "## Fortunately, we learned previously that it is typically much faster to work with matrices in **column major order** in CUDA because it allows **warps of threads** to access **consecutive memory locations**.  \n",
        "## To avoid using up too much memory we separate computing the large matrix product into pieces."
      ],
      "metadata": {
        "id": "FZRZdunWjb2S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The full details of how everything works together to achieve high performance in the CUDA code below is beyond the scope of this lecture.  \n",
        "\n",
        "## **If you are interested in learning more about programming for high performance in CUDA you should take CMDA 4634 (Scalable Computing for CMDA).**  "
      ],
      "metadata": {
        "id": "3zooOxknkWQ8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Reconnect to a T4 by running commands below.**"
      ],
      "metadata": {
        "id": "pl0c5uSYe2Eu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://code.vt.edu/jasonwil/cmda3634_materials.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Tg-aHPkp_HV",
        "outputId": "b4bacd79-f92c-43ea-f879-aa522608a0a5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'cmda3634_materials'...\n",
            "remote: Enumerating objects: 235, done.\u001b[K\n",
            "remote: Counting objects: 100% (196/196), done.\u001b[K\n",
            "remote: Compressing objects: 100% (173/173), done.\u001b[K\n",
            "remote: Total 235 (delta 86), reused 37 (delta 16), pack-reused 39 (from 1)\u001b[K\n",
            "Receiving objects: 100% (235/235), 47.75 MiB | 8.69 MiB/s, done.\n",
            "Resolving deltas: 100% (86/86), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# copy the lecture 20 files to our working directory\n",
        "!cp cmda3634_materials/L20/* .\n",
        "# uncompress the .gz files\n",
        "!gzip -d *.gz"
      ],
      "metadata": {
        "id": "Jj7WZfLtqBB5"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile gpu_extreme_v5.cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <float.h>\n",
        "#include <time.h>\n",
        "#include <cuda.h>\n",
        "#include <cublas_v2.h>\n",
        "\n",
        "typedef unsigned char byte;\n",
        "typedef unsigned long long uint64;\n",
        "\n",
        "// read data from a binary file\n",
        "void read_bin (byte* data, int num_bytes, char* filename, int header_size) {\n",
        "    byte header[header_size];\n",
        "    FILE* fptr;\n",
        "    int num_read;\n",
        "    // open the binary file for reading\n",
        "    fptr = fopen(filename,\"rb\");\n",
        "    // need to check for null\n",
        "    if (fptr == 0) {\n",
        "        printf (\"Error opening binary data file %s.\\n\",filename);\n",
        "        exit(1);\n",
        "    }\n",
        "    // read header\n",
        "    num_read = fread(header, sizeof(byte), header_size, fptr);\n",
        "    // read data\n",
        "    num_read = fread(data, sizeof(byte), num_bytes, fptr);\n",
        "    if (num_read != num_bytes) {\n",
        "        printf (\"Warning : binary data file read error for %s.\\n\",filename);\n",
        "    }\n",
        "    // close the binary file\n",
        "    fclose(fptr);\n",
        "}\n",
        "\n",
        "void extreme_info_expand(uint64 info, int* dist_sq, int* i, int* j) {\n",
        "    *j = info & 0xFFFF; // apply bit mask to zero out all but lower 16 bits\n",
        "    info = info >> 16; // shift 16 bits to the left\n",
        "    *i = info & 0xFFFF; // apply bit mask to zero out all but lower 16 bits\n",
        "    info = info >> 16; // shift 16 bits to the left\n",
        "    *dist_sq = info;\n",
        "}\n",
        "\n",
        "__device__ uint64 extreme_info_compress(int dist_sq, int i, int j) {\n",
        "    uint64 info = dist_sq;\n",
        "    info = info << 16; // shift 16 bits to the right\n",
        "    info += i;\n",
        "    info = info << 16; // shift 16 bits to the right\n",
        "    info += j;\n",
        "    return info;\n",
        "}\n",
        "\n",
        "__global__ void extremeKernel(float* dot_prods, float* i_j_dot_prods, int len,\n",
        "\t\t\t      int start, int size, uint64* max_info) {\n",
        "\n",
        "    int t = blockIdx.x*blockDim.x + threadIdx.x;\n",
        "    if (t < size) {\n",
        "\t    float term1 = dot_prods[t+start];\n",
        "        float max_dist_sq = 0;\n",
        "        int farthest_idx;\n",
        "\t    for (int j=0;j<t+start;j++) {\n",
        "            float term2 = term1 + dot_prods[j];\n",
        "            float term3 = i_j_dot_prods[j*size+t];\n",
        "            float dist_sq = term2 - 2.0*term3;\n",
        "            if (dist_sq > max_dist_sq) {\n",
        "                max_dist_sq = dist_sq;\n",
        "                farthest_idx = j;\n",
        "            }\n",
        "        }\n",
        "\t    uint64 info = extreme_info_compress((int)max_dist_sq,t+start,farthest_idx);\n",
        "\t    atomicMax(max_info,info);\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void dotprodsKernel (float *data, int len, int dim, float* dot_prods) {\n",
        "    int t = blockIdx.x*blockDim.x + threadIdx.x;\n",
        "    if (t < len) {\n",
        "        float result = 0;\n",
        "        for (int i=0;i<dim;i++) {\n",
        "            float term = data[i*len+t];\n",
        "            result += term*term;\n",
        "        }\n",
        "        dot_prods[t] = result;\n",
        "    }\n",
        "}\n",
        "\n",
        "int main (int argc, char** argv) {\n",
        "\n",
        "    // read in a MNIST image set\n",
        "    int len = 60000;\n",
        "    int dim = 784;\n",
        "    byte* data_bytes = (byte*)malloc(len*dim*sizeof(byte));\n",
        "    // read the file that thas the dataset stored in column major order\n",
        "    char images_file[] = \"train-images-idx3-ubyte-c\";\n",
        "    read_bin(data_bytes,len*dim,images_file,16);\n",
        "\n",
        "    // translate input data from byte to float matrices\n",
        "    // so that we can use CUBLAS\n",
        "    float* data = (float*)malloc(len*dim*sizeof(float));\n",
        "    for (int i=0;i<len*dim;i++) {\n",
        "        data[i] = data_bytes[i];\n",
        "    }\n",
        "\n",
        "    // allocate device memory\n",
        "    int size = 30000;\n",
        "    float* d_data;\n",
        "    uint64* d_max_info;\n",
        "    float* d_dot_prods;\n",
        "    float* d_i_j_dot_prods;\n",
        "    cudaMalloc(&d_data,len*dim*sizeof(float));\n",
        "    if (d_data == NULL) {\n",
        "\t    printf (\"cudaMalloc failed\\n\");\n",
        "\t    return 1;\n",
        "    }\n",
        "    cudaMalloc(&d_max_info,sizeof(uint64));\n",
        "    if (d_max_info == NULL) {\n",
        "\t    printf (\"cudaMalloc failed\\n\");\n",
        "\t    return 1;\n",
        "    }\n",
        "    cudaMalloc(&d_dot_prods,len*sizeof(float));\n",
        "    if (d_dot_prods == NULL) {\n",
        "\t    printf (\"cudaMalloc failed\\n\");\n",
        "\t    return 1;\n",
        "    }\n",
        "    cudaMalloc(&d_i_j_dot_prods,(long)size*len*sizeof(float));\n",
        "    if (d_i_j_dot_prods == NULL) {\n",
        "\t    printf (\"cudaMalloc failed\\n\");\n",
        "\t    return 1;\n",
        "    }\n",
        "\n",
        "    // start the timer\n",
        "    clock_t start = clock();\n",
        "\n",
        "    // copy data to device\n",
        "    cudaMemcpy(d_data,data,len*dim*sizeof(float),cudaMemcpyHostToDevice);\n",
        "\n",
        "    // initialize the device max_info to 0\n",
        "    cudaMemset(d_max_info,0,sizeof(uint64));\n",
        "\n",
        "    // launch kernel to compute i-i dot products\n",
        "    int B = 128;\n",
        "    int G = (len+B-1)/B;\n",
        "    dotprodsKernel <<< G, B >>> (d_data,len,dim,d_dot_prods);\n",
        "\n",
        "    // setup CUBLAS\n",
        "    float alpha = 1.0, beta = 0;\n",
        "    cublasHandle_t handle;\n",
        "    cublasCreate(&handle);\n",
        "    // this next command enables the Tensor Cores!\n",
        "    cublasSetMathMode(handle, CUBLAS_TENSOR_OP_MATH);\n",
        "\n",
        "    G = (size+B-1)/B;\n",
        "    for (int start = 0; start < len; start += size) {\n",
        "\n",
        "\t    // use CUBLAS to compute a batch of i-j dot products\n",
        "\t    cublasSgemm(handle, CUBLAS_OP_N, CUBLAS_OP_T,\n",
        "\t\t    size, len, dim, &alpha,\n",
        "\t\t    d_data+start, len,\n",
        "\t\t    d_data, len, &beta,\n",
        "\t\t    d_i_j_dot_prods, size);\n",
        "\t    cudaDeviceSynchronize();\n",
        "\n",
        "\t    // launch kernel to compute a batch of extreme distances\n",
        "\t    extremeKernel <<< G, B >>> (d_dot_prods,d_i_j_dot_prods,len,start,size,d_max_info);\n",
        "    }\n",
        "\n",
        "    // copy max_info from device to host\n",
        "    uint64 max_info;\n",
        "    cudaMemcpy(&max_info,d_max_info,sizeof(uint64),cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // stop the timer\n",
        "    clock_t stop = clock();\n",
        "    double elapsed = (double)(stop-start)/CLOCKS_PER_SEC;\n",
        "\n",
        "    // expand max_info\n",
        "    int max_dist_sq, i, j;\n",
        "    extreme_info_expand(max_info,&max_dist_sq,&i,&j);\n",
        "\n",
        "    // print results\n",
        "    printf (\"number of images = %d\\n\",len);\n",
        "    printf (\"elapsed time = %.4f seconds\\n\",elapsed);\n",
        "    printf (\"extreme distance = %.2f\\n\",sqrt(max_dist_sq));\n",
        "    printf (\"extreme pair = (%d,%d)\\n\",i,j);\n",
        "\n",
        "    // free dynamically allocated memory\n",
        "    free(data_bytes);\n",
        "    free(data);\n",
        "    cudaFree(d_data);\n",
        "    cudaFree(d_max_info);\n",
        "    cudaFree(d_dot_prods);\n",
        "    cudaFree(d_i_j_dot_prods);\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Mu6h3u9m8sR",
        "outputId": "514ccc77-cd33-4e5a-fec4-2dccffec4a39"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing gpu_extreme_v5.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 -o gpu_extreme_v5 gpu_extreme_v5.cu -lcublas"
      ],
      "metadata": {
        "id": "FzBegzBAdy81"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./gpu_extreme_v5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbBSO1I6gKte",
        "outputId": "bf95914e-856d-46d4-b498-50bc759d53a3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of images = 60000\n",
            "elapsed time = 0.6275 seconds\n",
            "extreme distance = 4303.32\n",
            "extreme pair = (59452,26785)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Disconnect and Delete T4 Runtime**"
      ],
      "metadata": {
        "id": "gqXcdnGheLOP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Change runtime type from T4 to CPU!**"
      ],
      "metadata": {
        "id": "2bqzmm6NeJwf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Recall that we have access to Nvidia A100 GPUs on ARC.\n",
        "## The A100 GPU is extremely fast at matrix multiplication.  \n",
        "## Here is a run on an A100 where we calculate the extreme pair of 60000 images."
      ],
      "metadata": {
        "id": "JtHb_61h4Jn9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "    [jasonwil@tc-dgx010]$ nvcc -arch=sm_80 -o gpu_extreme_v5 gpu_extreme_v5.cu -lcublas\n",
        "    [jasonwil@tc-dgx010]$ ./gpu_extreme_v5\n",
        "    number of images = 60000\n",
        "    elapsed time = 0.1015 seconds\n",
        "    extreme distance = 4303.32\n",
        "    extreme pair = (59452,26785)"
      ],
      "metadata": {
        "id": "eRW0E6YYy3e7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Recall that for the seqential code compiled with the optimization **-O3** turned on we calculated:\n",
        "\n",
        "    number of images = 60000\n",
        "    elapsed time = 203.6425 seconds\n",
        "    extreme distance = 4303.32\n",
        "    extreme pair = (26785,59452)"
      ],
      "metadata": {
        "id": "iAC6MS7N3V9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Note that speedup for 60000 images is\n",
        "## $$\\text{speedup} = \\displaystyle\\frac{\\text{Sequential Time}}{\\text{A100 GPU Time}} = \\displaystyle\\frac{203.6425}{0.1015} = 2006$$\n",
        "## **The A100 GPU is over 2000 times faster than the CPU for this problem!**"
      ],
      "metadata": {
        "id": "T8l304O35Btm"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Aco8mzCaeLUx"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}